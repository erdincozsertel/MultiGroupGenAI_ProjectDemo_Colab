{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJRpYt/jSmPcR4clycNQhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erdincozsertel/MultiGroupGenAI_ProjectDemo_Colab/blob/main/MultiGroupGenAI_ProjectDemo3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\"\"\"\n",
        "Movie/TV Recommender RAG Demo using Haystack & Gemini with Langfuse\n",
        "\n",
        "Adapted for Movie/TV Recommendations and Langfuse logging\n",
        "\"\"\"\n",
        "\n",
        "# --- 1. Install Dependencies ---\n",
        "!pip install -U -q haystack-ai google-ai-haystack sentence-transformers trafilatura langfuse-haystack hf_xet\n",
        "\n",
        "# --- 2. Set Up API Keys & Langfuse ---\n",
        "import os\n",
        "import logging\n",
        "from google.colab import userdata # Use Colab secrets for API keys\n",
        "from getpass import getpass\n",
        "\n",
        "# Fetch keys from Colab secrets\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    SERPERDEV_API_KEY = userdata.get('SERPERDEV_API_KEY')\n",
        "    # Langfuse Credentials\n",
        "    LANGFUSE_PUBLIC_KEY = userdata.get('LANGFUSE_PUBLIC_KEY')\n",
        "    LANGFUSE_SECRET_KEY = userdata.get('LANGFUSE_SECRET_KEY')\n",
        "    LANGFUSE_HOST = userdata.get('LANGFUSE_HOST')\n",
        "    if LANGFUSE_HOST is None:\n",
        "        LANGFUSE_HOST = \"https://cloud.langfuse.com\"\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "except userdata.SecretNotFoundError as e:\n",
        "    print(f\"API key or Langfuse credential not found in Colab Secrets: {e}. Please add them.\")\n",
        "    print(\"Secrets needed: GOOGLE_API_KEY, SERPERDEV_API_KEY, LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY (and optionally LANGFUSE_HOST)\")\n",
        "    raise ValueError(\"Required secrets not configured in Colab Secrets.\")\n",
        "\n",
        "\n",
        "# Set environment variables for Haystack components and Langfuse\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "os.environ[\"SERPERDEV_API_KEY\"] = SERPERDEV_API_KEY\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = LANGFUSE_PUBLIC_KEY\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = LANGFUSE_SECRET_KEY\n",
        "os.environ[\"LANGFUSE_HOST\"] = LANGFUSE_HOST\n",
        "os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "# Optional: Enable Haystack content tracing for debugging if needed (Langfuse also captures IO)\n",
        "os.environ[\"HAYSTACK_CONTENT_TRACING_ENABLED\"] = \"true\"\n",
        "\n",
        "# --- Logging Configuration ---\n",
        "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
        "logging.getLogger(\"haystack\").setLevel(logging.INFO)\n",
        "print(\"Inital setup is completed\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwH8v21LAQPM",
        "outputId": "dd3fe2b8-04a3-4370-96c0-b20a1ba9f94f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inital setup is completed\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# --- 3. Import Haystack Components ---\n",
        "from haystack import Pipeline, Document\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
        "from haystack.components.embedders import (\n",
        "    SentenceTransformersDocumentEmbedder,\n",
        "    SentenceTransformersTextEmbedder\n",
        ")\n",
        "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "from haystack.components.websearch import SerperDevWebSearch\n",
        "from haystack.components.builders import ChatPromptBuilder\n",
        "from haystack.components.routers import ConditionalRouter\n",
        "from haystack.dataclasses import ChatMessage\n",
        "from haystack_integrations.components.generators.google_ai.chat.gemini import GoogleAIGeminiChatGenerator\n",
        "# Import Langfuse Connector\n",
        "from haystack_integrations.components.connectors.langfuse import LangfuseConnector\n",
        "\n",
        "\n",
        "# --- 4. Define Document Store ---\n",
        "document_store = InMemoryDocumentStore()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "i2KN9yE0ARFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_SGS5tzFJVU"
      },
      "outputs": [],
      "source": [
        "# --- 3. Import Haystack Components ---\n",
        "\n",
        "from haystack import Pipeline, Document\n",
        "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
        "from haystack.components.embedders import (\n",
        "    SentenceTransformersDocumentEmbedder,\n",
        "    SentenceTransformersTextEmbedder\n",
        ")\n",
        "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
        "from haystack.components.websearch import SerperDevWebSearch\n",
        "from haystack.components.builders import ChatPromptBuilder\n",
        "from haystack.components.routers import ConditionalRouter\n",
        "from haystack.dataclasses import ChatMessage # Ensure ChatMessage is imported if not already\n",
        "from haystack_integrations.components.generators.google_ai.chat.gemini import GoogleAIGeminiChatGenerator\n",
        "from haystack_integrations.components.connectors.langfuse import LangfuseConnector\n",
        "\n",
        "# --- 4. Define Document Store ---\n",
        "document_store = InMemoryDocumentStore()"
      ]
    },
    {
      "source": [
        "# --- 5. Build Indexing Pipeline ---\n",
        "# (Indexing pipeline remains the same as before - Langfuse primarily traces query pipelines)\n",
        "print(\"Building Indexing Pipeline...\")\n",
        "indexing_pipeline = Pipeline()\n",
        "indexing_pipeline.add_component(instance=LinkContentFetcher(), name=\"fetcher\")\n",
        "indexing_pipeline.add_component(instance=HTMLToDocument(), name=\"converter\")\n",
        "indexing_pipeline.add_component(instance=DocumentCleaner(), name=\"cleaner\")\n",
        "indexing_pipeline.add_component(instance=DocumentSplitter(split_by=\"sentence\", split_length=10, split_overlap=2), name=\"splitter\")\n",
        "indexing_pipeline.add_component(instance=SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-mpnet-base-v2\"), name=\"embedder\")\n",
        "indexing_pipeline.add_component(instance=DocumentWriter(document_store=document_store), name=\"writer\")\n",
        "\n",
        "indexing_pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
        "indexing_pipeline.connect(\"converter.documents\", \"cleaner\")\n",
        "indexing_pipeline.connect(\"cleaner\", \"splitter\")\n",
        "indexing_pipeline.connect(\"splitter\", \"embedder\")\n",
        "indexing_pipeline.connect(\"embedder\", \"writer\")\n",
        "print(\"Indexing Pipeline Built.\")\n",
        "\n",
        "# --- 6. Index Your Data Sources ---\n",
        "urls_to_index = [\n",
        "  \"https://www.imdb.com/chart/top\",\n",
        "  \"https://www.imdb.com/chart/toptv\",\n",
        "  \"https://myanimelist.net/topanime.php\",\n",
        "  \"https://myanimelist.net/topanime.php?type=airing\",\n",
        "  \"https://myanimelist.net/topanime.php?type=upcoming\",\n",
        "  \"https://myanimelist.net/topanime.php?type=bypopularity\",\n",
        "  \"https://www.themoviedb.org/movie\",\n",
        "  \"https://www.themoviedb.org/tv\",\n",
        "  \"https://www.themoviedb.org/movie/now-playing\",\n",
        "  \"https://www.themoviedb.org/tv/on-the-air\"\n",
        "]\n",
        "\n",
        "if not document_store.count_documents():\n",
        "    print(f\"Indexing {len(urls_to_index)} URLs...\")\n",
        "    try:\n",
        "        indexing_pipeline.run({\"fetcher\": {\"urls\": urls_to_index}})\n",
        "        print(f\"Successfully indexed {document_store.count_documents()} documents.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during indexing: {e}\")\n",
        "else:\n",
        "     print(f\"Document store already contains {document_store.count_documents()} documents. Skipping indexing.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Yy8zLaCgAR71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# --- 7. Build Advanced RAG Query Pipeline with Langfuse ---\n",
        "print(\"Building Query Pipeline with Langfuse...\")\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "{% if web_documents %}\n",
        "    You were asked to answer the following query about movies/TV shows/anime based on the indexed documents, but the context was not enough.\n",
        "    Answer the question based on the given web search context.\n",
        "    Provide the sources/links you used from the web search context if possible.\n",
        "\n",
        "    User Question: {{ query }}\n",
        "\n",
        "    Web Search Context:\n",
        "    {% for document in web_documents %}\n",
        "    URL: {{document.meta.link}}\n",
        "    Content: {{document.content}}\n",
        "    ---\n",
        "    {% endfor %}\n",
        "{% else %}\n",
        "    You are a helpful assistant for recommending movies, TV series, and anime.\n",
        "    Answer the following query based ONLY on the documents provided below (e.g., top lists, descriptions).\n",
        "\n",
        "    Documents:\n",
        "    {% for document in documents %}\n",
        "    {{document.content}}\n",
        "    {% endfor %}\n",
        "\n",
        "    Query: {{query}}\n",
        "\n",
        "    Provide recommendations or answer the question based on the documents.\n",
        "    If the documents do NOT provide enough information to answer the query or give recommendations, ONLY output the text 'N0_ANSWER'. Do not add any other explanation.\n",
        "{% endif %}\n",
        "\"\"\"\n",
        "prompt = [ChatMessage.from_user(prompt_template)]\n",
        "\n",
        "main_routes = [\n",
        "    {\n",
        "        \"condition\": \"{{'N0_ANSWER' in replies[0].text.replace('\\\\n', '')}}\",\n",
        "        \"output\" :\"{{query}}\",\n",
        "        \"output_name\": \"go_web\",\n",
        "        \"output_type\": str,\n",
        "    },\n",
        "    {\n",
        "        \"condition\": \"{{'N0_ANSWER' not in replies[0].text.replace('\\\\n', '')}}\",\n",
        "        \"output\": \"{{replies[0].text}}\",\n",
        "        \"output_name\": \"answer\",\n",
        "        \"output_type\": str,\n",
        "    },\n",
        "]\n",
        "\n",
        "# Define the query pipeline\n",
        "query_pipeline = Pipeline(max_runs_per_component=5)\n",
        "\n",
        "# Add Langfuse Connector FIRST (or anywhere, it hooks automatically)\n",
        "# Name your Langfuse project appropriately\n",
        "query_pipeline.add_component(\"tracer\", LangfuseConnector(\"Movie Recommender RAG Demo 3\"))\n",
        "\n",
        "# Add the rest of the components\n",
        "query_pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-mpnet-base-v2\"))\n",
        "query_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))\n",
        "query_pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(template=prompt))\n",
        "query_pipeline.add_component(\"llm\", GoogleAIGeminiChatGenerator(model=\"gemini-1.5-flash\", generation_config={\"temperature\": 0.7}))\n",
        "query_pipeline.add_component(\"web_search\", SerperDevWebSearch())\n",
        "query_pipeline.add_component(\"router\", ConditionalRouter(main_routes))\n",
        "\n",
        "# Connect components (LangfuseConnector doesn't need explicit connection)\n",
        "query_pipeline.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
        "query_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "query_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
        "query_pipeline.connect(\"llm.replies\", \"router.replies\")\n",
        "query_pipeline.connect(\"router.go_web\", \"web_search.query\")\n",
        "query_pipeline.connect(\"web_search.documents\", \"prompt_builder.web_documents\")\n",
        "\n",
        "print(\"Query Pipeline Built with Langfuse.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BoCQYbBVAS74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# --- 8. Run a Query (Traces will be sent to Langfuse) ---\n",
        "print(\"\\n--- Running Sample Query (check Langfuse for trace) ---\")\n",
        "query = \"Recommend some highly rated sci-fi TV shows.\"\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "try:\n",
        "    pipeline_input = {\n",
        "        \"embedder\": {\"text\": query},\n",
        "        \"prompt_builder\": {\"query\": query},\n",
        "        \"router\": {\"query\": query}\n",
        "    }\n",
        "    result = query_pipeline.run(pipeline_input)\n",
        "\n",
        "    print(result[\"llm\"][\"replies\"])  # Inspect the replies structure\n",
        "\n",
        "    if \"answer\" in result.get(\"router\", {}):\n",
        "        final_answer = result[\"router\"][\"answer\"]\n",
        "        if isinstance(final_answer, list):\n",
        "             final_answer = final_answer[0] if final_answer else \"No answer found.\"\n",
        "        print(\"\\nAnswer:\")\n",
        "        print(final_answer)\n",
        "    else:\n",
        "         print(\"\\nSorry, I couldn't generate a recommendation based on the available information.\")\n",
        "         if \"documents\" in result.get(\"web_search\", {}):\n",
        "             print(\"\\nWeb Search Results considered:\")\n",
        "             for doc in result[\"web_search\"][\"documents\"]:\n",
        "                 print(f\"- {doc.meta.get('title', 'No Title')}: {doc.meta.get('link', 'No Link')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred while running the query: {e}\")\n",
        "\n",
        "# --- Example of another query ---\n",
        "print(\"\\n--- Running Another Query (check Langfuse for trace) ---\")\n",
        "query_2 = \"What is the plot of The Shawshank Redemption?\"\n",
        "print(f\"Query: {query_2}\")\n",
        "\n",
        "try:\n",
        "    pipeline_input_2 = {\n",
        "        \"embedder\": {\"text\": query_2},\n",
        "        \"prompt_builder\": {\"query\": query_2},\n",
        "        \"router\": {\"query\": query_2}\n",
        "    }\n",
        "    result_2 = query_pipeline.run(pipeline_input_2)\n",
        "\n",
        "    if \"answer\" in result_2.get(\"router\", {}):\n",
        "        final_answer_2 = result_2[\"router\"][\"answer\"]\n",
        "        if isinstance(final_answer_2, list):\n",
        "             final_answer_2 = final_answer_2[0] if final_answer_2 else \"No answer found.\"\n",
        "        print(\"\\nAnswer:\")\n",
        "        print(final_answer_2)\n",
        "    else:\n",
        "         print(\"\\nSorry, I couldn't generate an answer based on the available information.\")\n",
        "         if \"documents\" in result_2.get(\"web_search\", {}):\n",
        "             print(\"\\nWeb Search Results considered:\")\n",
        "             for doc in result_2[\"web_search\"][\"documents\"]:\n",
        "                 print(f\"- {doc.meta.get('title', 'No Title')}: {doc.meta.get('link', 'No Link')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred while running the query: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1H2XpnUIAT3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}